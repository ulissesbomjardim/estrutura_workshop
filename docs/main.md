# ğŸ¯ Main â€” MÃ³dulo Principal

Este Ã© o mÃ³dulo principal que orquestra todo o pipeline ETL do projeto, coordenando a execuÃ§Ã£o das trÃªs etapas fundamentais.

---

## ğŸ¯ VisÃ£o Geral

O mÃ³dulo `main.py` Ã© o **ponto de entrada** do pipeline ETL, responsÃ¡vel por:

- ğŸ¼ **Orquestrar** todo o fluxo de dados
- ğŸ“¥ **Coordenar** a extraÃ§Ã£o de dados
- âš™ï¸ **Gerenciar** a transformaÃ§Ã£o
- ğŸ“¤ **Controlar** o carregamento
- ğŸ“Š **Monitorar** o progresso

---

## ğŸ”§ Funcionalidades

### âœ… **Capacidades**:
- ğŸ¼ OrquestraÃ§Ã£o completa do pipeline
- ğŸ“‹ ConfiguraÃ§Ã£o centralizadas de caminhos
- ğŸ“Š Monitoramento de tipos de dados
- âœ… Feedback visual do progresso

### âš¡ **Performance**:
- ğŸš€ ExecuÃ§Ã£o sequencial otimizada
- ğŸ’¾ GestÃ£o eficiente de memÃ³ria
- ğŸ”„ Processamento em lote

---

## ğŸ“– DocumentaÃ§Ã£o da API

### ğŸ¯ **FunÃ§Ã£o Principal**

::: src.main.main

---

## ğŸ’» CÃ³digo Fonte Completo

```python
from pipeline.extract import extract_from_excel
from pipeline.load import load_to_excel
from pipeline.transform import transform_data


def main() -> None:
    input_path = "data/input"
    output_path = "data/output"
    filename = "dados_concatenados"

    data_list = extract_from_excel(input_path)
    print(type(data_list))

    data_frame = transform_data(data_list)
    print(type(data_frame))

    message = load_to_excel(data_frame, output_path, filename)
    print(message)


if __name__ == "__main__":
    main()
```

---

## ğŸ”„ Fluxo de ExecuÃ§Ã£o

```mermaid
graph LR
    A[ğŸš€ Iniciar] --> B[ğŸ“ Configurar Caminhos]
    B --> C[ğŸ“¥ Extract]
    C --> D[ğŸ“Š Verificar Tipos]
    D --> E[âš™ï¸ Transform]
    E --> F[ğŸ“Š Verificar Tipos]
    F --> G[ğŸ“¤ Load]
    G --> H[âœ… Confirmar Sucesso]
    H --> I[ğŸ Finalizar]

    style A fill:#e3f2fd
    style C fill:#f3e5f5
    style E fill:#fff3e0
    style G fill:#e8f5e8
    style I fill:#e8f5e8
```

---

## âš™ï¸ ConfiguraÃ§Ã£o e ParÃ¢metros

### ğŸ“ **Caminhos de Dados**
```python
# ConfiguraÃ§Ãµes centralizadas
input_path = "data/input"      # ğŸ“¥ Dados de entrada
output_path = "data/output"    # ğŸ“¤ Dados de saÃ­da
filename = "dados_concatenados" # ğŸ·ï¸ Nome do arquivo final
```

### ğŸ”§ **PersonalizaÃ§Ã£o**
```python
def main_customized(input_dir: str = "data/input",
                   output_dir: str = "data/output",
                   output_name: str = "resultado") -> None:
    """VersÃ£o customizÃ¡vel da funÃ§Ã£o main"""

    print(f"ğŸ“¥ Extraindo de: {input_dir}")
    data_list = extract_from_excel(input_dir)
    print(f"âœ… ExtraÃ­dos {len(data_list)} arquivos")

    print(f"âš™ï¸ Transformando dados...")
    data_frame = transform_data(data_list)
    print(f"âœ… Dados consolidados: {data_frame.shape}")

    print(f"ğŸ“¤ Salvando em: {output_dir}/{output_name}.xlsx")
    message = load_to_excel(data_frame, output_dir, output_name)
    print(f"âœ… {message}")
```

---

## ğŸ“Š Monitoramento e Debug

### ğŸ” **InformaÃ§Ãµes de Debug**
```python
def main_verbose() -> None:
    """VersÃ£o com informaÃ§Ãµes detalhadas"""

    input_path = "data/input"
    output_path = "data/output"
    filename = "dados_concatenados"

    print("ğŸš€ Iniciando pipeline ETL...")

    # Extract
    print("ğŸ“¥ Fase 1: ExtraÃ§Ã£o")
    data_list = extract_from_excel(input_path)
    print(f"   ğŸ“Š Tipo: {type(data_list)}")
    print(f"   ğŸ“‹ Arquivos: {len(data_list)}")
    for i, df in enumerate(data_list):
        print(f"   ğŸ“„ Arquivo {i+1}: {df.shape}")

    # Transform
    print("âš™ï¸ Fase 2: TransformaÃ§Ã£o")
    data_frame = transform_data(data_list)
    print(f"   ğŸ“Š Tipo: {type(data_frame)}")
    print(f"   ğŸ“ Shape: {data_frame.shape}")
    print(f"   ğŸ·ï¸ Colunas: {list(data_frame.columns)}")

    # Load
    print("ğŸ“¤ Fase 3: Carregamento")
    message = load_to_excel(data_frame, output_path, filename)
    print(f"   âœ… {message}")

    print("ğŸ Pipeline concluÃ­do com sucesso!")
```

### ğŸ“ˆ **MÃ©tricas de Performance**
```python
import time
from typing import Dict, Any

def main_with_metrics() -> Dict[str, Any]:
    """VersÃ£o com mÃ©tricas de performance"""

    metrics = {}
    start_time = time.time()

    input_path = "data/input"
    output_path = "data/output"
    filename = "dados_concatenados"

    # Extract
    extract_start = time.time()
    data_list = extract_from_excel(input_path)
    extract_time = time.time() - extract_start
    metrics['extract_time'] = extract_time
    metrics['files_processed'] = len(data_list)

    # Transform
    transform_start = time.time()
    data_frame = transform_data(data_list)
    transform_time = time.time() - transform_start
    metrics['transform_time'] = transform_time
    metrics['final_rows'] = len(data_frame)
    metrics['final_columns'] = len(data_frame.columns)

    # Load
    load_start = time.time()
    message = load_to_excel(data_frame, output_path, filename)
    load_time = time.time() - load_start
    metrics['load_time'] = load_time

    # Total
    total_time = time.time() - start_time
    metrics['total_time'] = total_time

    print("ğŸ“Š MÃ©tricas de Performance:")
    print(f"   ğŸ“¥ ExtraÃ§Ã£o: {extract_time:.2f}s")
    print(f"   âš™ï¸ TransformaÃ§Ã£o: {transform_time:.2f}s")
    print(f"   ğŸ“¤ Carregamento: {load_time:.2f}s")
    print(f"   ğŸ• Total: {total_time:.2f}s")

    return metrics
```

---

## ğŸ› ï¸ Tratamento de Erros

### ğŸ”§ **VersÃ£o Robusta**
```python
def main_robust() -> bool:
    """VersÃ£o com tratamento de erros"""

    try:
        input_path = "data/input"
        output_path = "data/output"
        filename = "dados_concatenados"

        # Extract
        print("ğŸ“¥ Extraindo dados...")
        data_list = extract_from_excel(input_path)

        if not data_list:
            print("âŒ Nenhum arquivo encontrado para processar")
            return False

        print(f"âœ… {len(data_list)} arquivos extraÃ­dos")

        # Transform
        print("âš™ï¸ Transformando dados...")
        data_frame = transform_data(data_list)
        print(f"âœ… Dados consolidados: {data_frame.shape}")

        # Load
        print("ğŸ“¤ Salvando resultado...")
        message = load_to_excel(data_frame, output_path, filename)
        print(f"âœ… {message}")

        return True

    except FileNotFoundError as e:
        print(f"âŒ Arquivo nÃ£o encontrado: {e}")
        return False
    except ValueError as e:
        print(f"âŒ Erro de dados: {e}")
        return False
    except Exception as e:
        print(f"âŒ Erro inesperado: {e}")
        return False
```

---

## ğŸš€ Formas de ExecuÃ§Ã£o

### âš¡ **ExecuÃ§Ã£o PadrÃ£o**
```bash
# Via Poetry (recomendado)
poetry run python src/main.py

# Via task
poetry run task run

# Com shell ativo
poetry shell
python src/main.py
```

### ğŸ”§ **ExecuÃ§Ã£o Customizada**
```python
# Em um script ou notebook
from src.main import main

# ExecuÃ§Ã£o normal
main()

# Ou importar e executar partes
from src.pipeline.extract import extract_from_excel
from src.pipeline.transform import transform_data
from src.pipeline.load import load_to_excel

# ExecuÃ§Ã£o manual das etapas
data_list = extract_from_excel("data/input")
df = transform_data(data_list)
load_to_excel(df, "data/output", "meu_resultado")
```

---

## ğŸ“Š SaÃ­da Esperada

### âœ… **ExecuÃ§Ã£o Bem-sucedida**
```
<class 'list'>
<class 'pandas.core.frame.DataFrame'>
arquivo xlsx salvo com sucesso
```

### ğŸ“‹ **InterpretaÃ§Ã£o**
- **Linha 1**: Confirma que `extract_from_excel` retorna uma lista
- **Linha 2**: Confirma que `transform_data` retorna um DataFrame
- **Linha 3**: Confirma que `load_to_excel` salvou com sucesso

---

## ğŸ§ª Testes

### ğŸ“‹ **Testes IncluÃ­dos**
- âœ… ExecuÃ§Ã£o completa do pipeline via `runpy`
- âœ… VerificaÃ§Ã£o de chamadas de funÃ§Ã£o com mocks
- âœ… ValidaÃ§Ã£o de saÃ­da impressa
- âœ… Teste de integraÃ§Ã£o end-to-end

### ğŸ”§ **Executar Testes**
```bash
# Testes especÃ­ficos do main
poetry run pytest tests/test_pipeline.py -v

# Teste de integraÃ§Ã£o
poetry run pytest tests/test_pipeline.py::test_main_integration -v
```

---

## ğŸ”„ ExtensÃµes PossÃ­veis

### ğŸ“Š **Logging**
```python
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def main_with_logging() -> None:
    """VersÃ£o com logging estruturado"""

    logger.info("Iniciando pipeline ETL")

    # Extract
    logger.info("Fase: ExtraÃ§Ã£o")
    data_list = extract_from_excel("data/input")
    logger.info(f"ExtraÃ­dos {len(data_list)} arquivos")

    # Transform
    logger.info("Fase: TransformaÃ§Ã£o")
    data_frame = transform_data(data_list)
    logger.info(f"Dados consolidados: {data_frame.shape}")

    # Load
    logger.info("Fase: Carregamento")
    message = load_to_excel(data_frame, "data/output", "dados_concatenados")
    logger.info(f"Resultado: {message}")

    logger.info("Pipeline concluÃ­do")
```

### ğŸ”§ **ConfiguraÃ§Ã£o Externa**
```python
import json
from pathlib import Path

def main_with_config(config_path: str = "config.json") -> None:
    """VersÃ£o com arquivo de configuraÃ§Ã£o"""

    # Carregar configuraÃ§Ã£o
    if Path(config_path).exists():
        with open(config_path, 'r') as f:
            config = json.load(f)
    else:
        config = {
            "input_path": "data/input",
            "output_path": "data/output",
            "filename": "dados_concatenados"
        }

    # Executar pipeline
    data_list = extract_from_excel(config["input_path"])
    data_frame = transform_data(data_list)
    message = load_to_excel(
        data_frame,
        config["output_path"],
        config["filename"]
    )

    print(f"âœ… Pipeline executado: {message}")
```

---

## ğŸ”— PrÃ³ximos Passos

- ğŸ“¥ **Extract**: [ğŸ“¥ Extract](extract.md) - Primeiro estÃ¡gio do pipeline
- âš™ï¸ **Transform**: [âš™ï¸ Transform](transform.md) - Segundo estÃ¡gio
- ğŸ“¤ **Load**: [ğŸ“¤ Load](load.md) - Terceiro estÃ¡gio
- ğŸ“– **Overview**: [ğŸ“– CÃ³digo](codigo.md) - VisÃ£o geral da arquitetura
